🔍 𝗦𝗲𝗹𝗳-𝗥𝗲𝘃𝗶𝗲𝘄𝗶𝗻𝗴 𝗠𝘆 𝗢𝘄𝗻 𝗥𝗲𝘀𝗲𝗮𝗿𝗰𝗵: 𝗣𝗮𝗽𝗲𝗿 #𝟭 



👉 𝗥𝗲𝗮𝗱 𝘁𝗵𝗲 𝗜𝗻𝘁𝗿𝗼𝗱𝘂𝗰𝘁𝗶𝗼𝗻 𝗣𝗼𝘀𝘁 𝗵𝗲𝗿𝗲: https://lnkd.in/eS_FjQHF



✅ 𝗣𝗮𝗽𝗲𝗿: Measuring Time-Varying Information Flow in Scalp EEG Signals: Orthogonalized Partial Directed Coherence

𝗝𝗼𝘂𝗿𝗻𝗮𝗹: IEEE Transactions on Biomedical Engineering, 2014




✅ 𝗥𝗲𝘃𝗶𝗲𝘄𝗲𝗿 #𝟮 𝗖𝗼𝗺𝗺𝗲𝗻𝘁𝘀



 1. 𝗢𝘃𝗲𝗿𝗰𝗹𝗮𝗶𝗺𝗲𝗱 𝗻𝗼𝘃𝗲𝗹𝘁𝘆: gOPDC is sold as a breakthrough, but it is really a patchwork of old ideas (PDC, gPDC, orthogonalization, imaginary coherence). Repackaging ≠ innovation.



 2. 𝗪𝗲𝗮𝗸 𝘁𝗵𝗲𝗼𝗿𝘆: The supposed “cure” for volume conduction has no proof, just heuristics. No guarantee it truly eliminates spurious links.



 3. 𝗧𝗼𝘆 𝘀𝗶𝗺𝘂𝗹𝗮𝘁𝗶𝗼𝗻𝘀: The synthetic MVAR models are trivial and unrealistic. Random linear mixing is not a serious proxy for EEG forward modeling.



 4. 𝗧𝗶𝗻𝘆 𝗿𝗲𝗮𝗹 𝗱𝗮𝘁𝗮𝘀𝗲𝘁: Only 4 neonates. Over-preprocessed, artifact-stripped signals. Way too small to justify the sweeping claims about robustness and clinical potential.



 5. 𝗦𝗵𝗮𝗸𝘆 𝘀𝘁𝗮𝘁𝗶𝘀𝘁𝗶𝗰𝘀: The baseline-threshold approach likely underestimates false positives. Ignoring stronger surrogate approaches makes the conclusions questionable.



 6. 𝗠𝗶𝘀𝗹𝗲𝗮𝗱𝗶𝗻𝗴 𝘃𝗶𝘀𝘂𝗮𝗹𝘀: Pretty 3D head plots of arrows create an illusion of “networks” but lack validation against ground truth. Risk of eye candy over science.



 7. 𝗔𝗿𝗯𝗶𝘁𝗿𝗮𝗿𝘆 𝗺𝗼𝗱𝗲𝗹 𝗼𝗿𝗱𝗲𝗿: Fixing p=5 because higher orders failed is a methodological shortcut. Low-order models distort spectral structure, especially in neonatal EEG.



 8. 𝗜𝗴𝗻𝗼𝗿𝗲𝗱 𝗰𝗼𝗺𝗽𝘂𝘁𝗮𝘁𝗶𝗼𝗻𝗮𝗹 𝗰𝗼𝘀𝘁: DEKF is heavy and impractical for large EEG sets, yet this was brushed aside. Real-world scalability is doubtful.



 9. 𝗡𝗼 𝗯𝗲𝗻𝗰𝗵𝗺𝗮𝗿𝗸𝗶𝗻𝗴: Comparison only with gPDC. Completely ignores nonlinear and information-theoretic methods already available at the time.



 10. 𝗢𝘃𝗲𝗿𝗵𝘆𝗽𝗲𝗱 𝗰𝗹𝗶𝗻𝗶𝗰𝗮𝗹 𝗰𝗹𝗮𝗶𝗺𝘀: Suggestions about prognosis after birth asphyxia or subcortical integrity are speculative at best. Reads more like a grant pitch than cautious science.



✅ 𝗢𝘃𝗲𝗿𝗮𝗹𝗹 𝗔𝘀𝘀𝗲𝘀𝘀𝗺𝗲𝗻𝘁

This work is incremental, not groundbreaking. Validation is thin, simulations unrealistic, data far too small, and clinical claims overblown. The method may have technical interest, but the paper overstates its contribution.



✅ 𝗪𝗵𝗮𝘁 𝗜 𝘄𝗼𝘂𝗹𝗱 𝗱𝗼 𝗱𝗶𝗳𝗳𝗲𝗿𝗲𝗻𝘁𝗹𝘆 𝘁𝗼𝗱𝗮𝘆:

 • Base simulations on realistic EEG forward models.

 • Use larger, more diverse datasets.

 • Benchmark against modern nonlinear methods.

 • Explicitly acknowledge methodological limits instead of inflating claims.



✅ 𝗢𝘃𝗲𝗿𝗮𝗹𝗹 𝗾𝘂𝗮𝗹𝗶𝘁𝘆: Technically interesting, but methodologically weak and overhyped.



#MedicalDataAnalysis #Neuroimaging #ResearchReflection #ScientificIntegrity #Reviewer2OnMyPapers
